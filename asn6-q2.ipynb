{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question 2\n",
    "\n",
    "In this question we will:\n",
    "\n",
    "- Use a pre-trained Inception-V3 network and transfer learning to solve the cat/dog classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 0: Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# THIS VERSION IS FOR TENSORFLOW v2.0 which has keras embedded\n",
    "# Note: Multibackend Keras is being discontinued after version 2.3.5.\n",
    "\n",
    "# These are all the imports we will need.  You shouldn't need anything else.\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import os as os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset sizes\n",
    "num_train_images = 23000\n",
    "num_validation_images = 2000\n",
    "num_test_images = 399\n",
    "\n",
    "# Some Hyperparameters\n",
    "input_image_size = 256\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "l2_lambda = 0.01\n",
    "\n",
    "# Parameters derived from hyperparameters\n",
    "training_steps_per_epoch = int(num_train_images/batch_size)\n",
    "validation_steps = int(num_validation_images/batch_size)\n",
    "testing_steps_per_epoch = num_test_images/batch_size\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " # Step 1: Load the Inception V3 network, and modify it for transfer learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled!\n"
     ]
    }
   ],
   "source": [
    "# WRITE THE CODE DEFINING THE NETWORK ARCHITECTURE HERE (Sec. 3.9 in the assignment PDF)\n",
    "\n",
    "# Our model will be Inception V3 with the fully connected layers and ouptut layers at the end of the network removed.\n",
    "# For the convolutional layers we will use pre-trained weights from the ImageNET database.\n",
    "\n",
    "# Instantiate an InceptionV3() object with weights='imagenet', input_shape = (input_image_size, input_image_size, 3), \n",
    "# and include_top=False.  Assign the result to the base_model variable.\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', input_shape=(input_image_size, input_image_size, 3), include_top=False)\n",
    "\n",
    "# Get the output layer of our base model. \n",
    "x = base_model.output\n",
    "\n",
    "# Now we want to add some layers to the end of the base model.  \n",
    "# Given an output layer x, the general syntax for adding a new layer is:\n",
    "#\n",
    "# x = LayerObject()(x)\n",
    "#\n",
    "# where LayerObject() is the constructor for a new layer object.  \n",
    "# The new value for x is the new output layer of the model.\n",
    "\n",
    "# Add a GlobalAveragePooling2D() object to the network.  No parameters are needed when instantiating GlobalAveragePooling2D().\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "\n",
    "# Add a Flatten() layer to the network.  No parameters are needed when instantiating Flatten().\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "# Add a Dense() layer.  Dense() is the fully-connected layer object you used in the Question 1.  \n",
    "# Instantiate it so that it has 1024 units, and uses the Relu activation function.\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "\n",
    "# Add another dense layer with 1 unit and the sigmoid activation function.  This will be your output layer.\n",
    "# Assign the result to the 'predictions' variable.\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Wrap our network layers in a model object. This has to be done because the base_model is not a Model() object, it's\n",
    "# just a collection of layer objects, and only Model() objects can be compiled.  Here we just tell the Model object \n",
    "# that its first layer is the input layer of the base Inception V3 model and the output layer is our new sigmoid layer.  \n",
    "# This is all the Model object needs beacuse all the other layer objects already know how they are connected.\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Set all the layers in the base model to be non-trainable.  \n",
    "# This freezes the weights in the convolutional layers so that, when we train,\n",
    "# we are only training the weights for the newly added fully connected layer.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False;\n",
    "        \n",
    "# Create an Adam optimizer object with learning rate equal to learning_rate (defined above);\n",
    "# call Adam() with the parameter lr=learning_rate\n",
    "\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "\n",
    "# Compile the CNN using model.compile() method.  Use the 'adam' optimizer you created above, and the \n",
    "# 'binary_crossentropy' loss function.  Use the parameter metrics=['accuracy'].  \n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Print a Summary of the Architecture using the summary() method.\n",
    "#model.summary()     # If you want to see the model, uncomment this line.  It's really big!\n",
    "\n",
    "print('Model compiled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 2: Load Images and Prepare the Network for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# This is nearly identical to step 2 from question 1 with a few minor changes (watch for them!)\n",
    "\n",
    "# Create the training dataset generator.  This time do not use shearing or zooming, just horizontal flipping.\n",
    "# Don't forget to rescale the image pixel data.\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "# Create the validation dataset generator.  It doesn't need any data augmentation.\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the training set using train_datagen.flow_from_directory().  Use\n",
    "# target_size = (input_image_size, input_image_size), batch_size = batch_size, and class_mode = 'binary'.\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\ducth\\\\cmpt 487 asm\\\\asm6\\\\train\" ,\n",
    "    target_size=(input_image_size, input_image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "\n",
    "# Load the validation dataset using validation_datagen.flow_from_directory(). \n",
    "# Use the same parameters as above (except for the directory name).\n",
    "\n",
    "validation_set = validation_datagen.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\ducth\\\\cmpt 487 asm\\\\asm6\\\\valid\" ,\n",
    "    target_size=(input_image_size, input_image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 3: Run the CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718/718 [==============================] - 781s 1s/step - loss: 0.0553 - accuracy: 0.9827 - val_loss: 0.0342 - val_accuracy: 0.9874\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN using model.fit().  \n",
    "# This works just like in the previous Question 1 problem -- use the provided model hyperparameters defined in the top block of this notebook.\n",
    "# Note, however, that this time num_epochs has been set to 1.  This means we will only train for one epoch!\n",
    "\n",
    "# This can take a while - maybe up to 2-3 hours depending on your CPU.   On my computer (which is an M2 macbook pro) \n",
    "# it took about 10 minutes training on the CPU (not GPU).  \n",
    "\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    steps_per_epoch=training_steps_per_epoch,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 4: Save the model and weights for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ducth\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the model using the save() method of the CNN model.\n",
    "# Inception is a big network, so this can take quite a while... \n",
    "# be patient and wait for the message indicating that the model has been saved.\n",
    "\n",
    "# You don't have to code anything here except change the filename if required.\n",
    "\n",
    "model.save('Cat-Dog-transfer-Inception.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " # Step 5: Predict Dog/Cat using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ducth\\AppData\\Local\\Temp\\ipykernel_18108\\4285891948.py:16: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  probabilities = model.predict_generator(generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification rate is 98.25%\n"
     ]
    }
   ],
   "source": [
    "# This can be done in exactly the same way as in Question 1.  Just make sure to load the right model file.\n",
    "\n",
    "# You should get a *very* high classification rate.\n",
    "\n",
    "model = load_model('Cat-Dog-transfer-Inception.h5')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = test_datagen.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\ducth\\\\cmpt 487 asm\\\\asm6\\\\test1\",\n",
    "    target_size=(input_image_size, input_image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "probabilities = model.predict_generator(generator)\n",
    "\n",
    "y_pred = np.squeeze((probabilities > 0.5).astype(int))\n",
    "\n",
    "accuracy = np.sum(y_pred == generator.classes) / len(generator.classes)\n",
    "accuracy_percentage = (accuracy * 100)\n",
    "\n",
    "print(f'The classification rate is {accuracy_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Final Remarks\n",
    "\n",
    "This exercise shows the potential advantage of transfer learning.  We were able to use a very large and sophisticated model, but avoid most of the work of training it by using weights trained by someone else on a different, but quite general dataset.  All we had to do was fine-tune the weights of a fresh randomly-initialized fully connected layer.  The training time per epoch is a lot more because the model is much larger than our model in Question 1, but we only needed to train for one epoch.\n",
    "\n",
    "We only used one training epoch, and even though that got us a very good model, we might see improvements if we train for additional epochs (at the cost of that much more time!).\n",
    "\n",
    "We might also be able to improve our model further by fine-tuning the weights of some of the convolutional layers.  For example, we could add a second training phase where we un-freeze the weights of the first few convolutional layers, and train them along with the fully connected layers for a few more epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
